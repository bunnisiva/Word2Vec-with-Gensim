{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to build Word2Vec model, and load Newsgroups data\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "TEXT_DATA_DIR = './20news-bydate-train/'   # I only train on this my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newsgroups data is split between many files and folders.\n",
    "# Directory stucture ./20news-bydate-train/<newsgroup label>/<post ID>\n",
    "\n",
    "texts = []         # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []        # list of label ids\n",
    "label_text = []    # list of label texts\n",
    "\n",
    "# Go through each directory\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            # News groups posts are named as numbers, with no extensions.\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                f = open(fpath, encoding='latin-1')\n",
    "                t = f.read()\n",
    "                i = t.find('\\n\\n')  # skip header in file (starts with two newlines.)\n",
    "                if 0 < i:\n",
    "                    t = t[i:]\n",
    "                texts.append(t)\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "                label_text.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'talk.politics.mideast': 17, 'talk.politics.guns': 16, 'comp.os.ms-windows.misc': 2, 'comp.windows.x': 5, 'soc.religion.christian': 15, 'alt.atheism': 0, 'comp.graphics': 1, 'rec.sport.baseball': 9, 'talk.politics.misc': 18, 'rec.sport.hockey': 10, 'sci.crypt': 11, 'sci.med': 13, 'talk.religion.misc': 19, 'sci.space': 14, 'rec.autos': 7, 'rec.motorcycles': 8, 'comp.sys.ibm.pc.hardware': 3, 'comp.sys.mac.hardware': 4, 'misc.forsale': 6, 'sci.electronics': 12}\n"
     ]
    }
   ],
   "source": [
    "print (labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) # total labelled text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)  # total texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_text) # name of the labels also the folder name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_id # numerical tag for the label classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) # there are 11314 ground truth labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[11312] # 11312th text belong to class label19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk.religion.misc'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_text[11312]# folder the text 11312 is located in , also it is the category this text belongs to in the newapAaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11314 texts.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data is loaded into memory (a single list ‘texts’) at this point; for preprocessing, remove all punctuation, and excess information.Gensim likes this form for input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data - remove punctuation from every newsgroup text\n",
    "sentences = []\n",
    "# Go through each text in turn\n",
    "for ii in range(len(texts)):\n",
    "    sentences = [re.sub(pattern=r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]', \n",
    "                        repl='', \n",
    "                        string=x\n",
    "                       ).strip().split(' ') for x in texts[ii].split('\\n') \n",
    "                      if not x.endswith('writes:')]\n",
    "    sentences = [x for x in sentences if x != ['']]\n",
    "    texts[ii] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Archivename', 'atheismresources'], ['Altatheismarchivename', 'resources'], ['Lastmodified', '11', 'December', '1992'], ['Version', '10'], ['Atheist', 'Resources'], ['Addresses', 'of', 'Atheist', 'Organizations'], ['USA'], ['FREEDOM', 'FROM', 'RELIGION', 'FOUNDATION'], ['Darwin', 'fish', 'bumper', 'stickers', 'and', 'assorted', 'other', 'atheist', 'paraphernalia', 'are'], ['available', 'from', 'the', 'Freedom', 'From', 'Religion', 'Foundation', 'in', 'the', 'US'], ['Write', 'to', '', 'FFRF', 'PO', 'Box', '750', 'Madison', 'WI', '53701'], ['Telephone', '608', '2568900'], ['EVOLUTION', 'DESIGNS'], ['Evolution', 'Designs', 'sell', 'the', 'Darwin', 'fish', '', \"It's\", 'a', 'fish', 'symbol', 'like', 'the', 'ones'], ['Christians', 'stick', 'on', 'their', 'cars', 'but', 'with', 'feet', 'and', 'the', 'word', 'Darwin', 'written'], ['inside', '', 'The', 'deluxe', 'moulded', '3D', 'plastic', 'fish', 'is', '495', 'postpaid', 'in', 'the', 'US'], ['Write', 'to', '', 'Evolution', 'Designs', '7119', 'Laurel', 'Canyon', '4', 'North', 'Hollywood'], ['CA', '91605'], ['People', 'in', 'the', 'San', 'Francisco', 'Bay', 'area', 'can', 'get', 'Darwin', 'Fish', 'from', 'Lynn', 'Gold'], ['try', 'mailing', 'figmonetcomcom', '', 'For', 'net', 'people', 'who', 'go', 'to', 'Lynn', 'directly', 'the'], ['price', 'is', '495', 'per', 'fish'], ['AMERICAN', 'ATHEIST', 'PRESS'], ['AAP', 'publish', 'various', 'atheist', 'books', '', 'critiques', 'of', 'the', 'Bible', 'lists', 'of'], ['Biblical', 'contradictions', 'and', 'so', 'on', '', 'One', 'such', 'book', 'is'], ['The', 'Bible', 'Handbook', 'by', 'WP', 'Ball', 'and', 'GW', 'Foote', '', 'American', 'Atheist', 'Press'], ['372', 'pp', '', 'ISBN', '0910309264', '2nd', 'edition', '1986', '', 'Bible', 'contradictions'], ['absurdities', 'atrocities', 'immoralities', 'contains', 'Ball', 'Foote', 'The', 'Bible'], ['Contradicts', 'Itself', 'AAP', '', 'Based', 'on', 'the', 'King', 'James', 'version', 'of', 'the', 'Bible'], ['Write', 'to', '', 'American', 'Atheist', 'Press', 'PO', 'Box', '140195', 'Austin', 'TX', '787140195'], ['or', '', '7215', 'Cameron', 'Road', 'Austin', 'TX', '787522973'], ['Telephone', '512', '4581244'], ['Fax', '', '', '', '', '', '', '512', '4679525'], ['PROMETHEUS', 'BOOKS'], ['Sell', 'books', 'including', \"Haught's\", 'Holy', 'Horrors', 'see', 'below'], ['Write', 'to', '', '700', 'East', 'Amherst', 'Street', 'Buffalo', 'New', 'York', '14215'], ['Telephone', '716', '8372475'], ['An', 'alternate', 'address', 'which', 'may', 'be', 'newer', 'or', 'older', 'is'], ['Prometheus', 'Books', '59', 'Glenn', 'Drive', 'Buffalo', 'NY', '142282197'], ['AFRICANAMERICANS', 'FOR', 'HUMANISM'], ['An', 'organization', 'promoting', 'black', 'secular', 'humanism', 'and', 'uncovering', 'the', 'history', 'of'], ['black', 'freethought', '', 'They', 'publish', 'a', 'quarterly', 'newsletter', 'AAH', 'EXAMINER'], ['Write', 'to', '', 'Norm', 'R', 'Allen', 'Jr', 'African', 'Americans', 'for', 'Humanism', 'PO', 'Box', '664'], ['Buffalo', 'NY', '14226'], ['United', 'Kingdom'], ['Rationalist', 'Press', 'Association', '', '', '', '', '', '', '', '', '', 'National', 'Secular', 'Society'], ['88', 'Islington', 'High', 'Street', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '702', 'Holloway', 'Road'], ['London', 'N1', '8EW', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'London', 'N19', '3NL'], ['071', '226', '7251', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '071', '272', '1266'], ['British', 'Humanist', 'Association', '', '', '', '', '', '', '', '', '', '', 'South', 'Place', 'Ethical', 'Society'], ['14', \"Lamb's\", 'Conduit', 'Passage', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Conway', 'Hall'], ['London', 'WC1R', '4RH', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Red', 'Lion', 'Square'], ['071', '430', '0908', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'London', 'WC1R', '4RL'], ['fax', '071', '430', '1271', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '071', '831', '7723'], ['The', 'National', 'Secular', 'Society', 'publish', 'The', 'Freethinker', 'a', 'monthly', 'magazine'], ['founded', 'in', '1881'], ['Germany'], ['IBKA', 'eV'], ['Internationaler', 'Bund', 'der', 'Konfessionslosen', 'und', 'Atheisten'], ['Postfach', '880', 'D1000', 'Berlin', '41', 'Germany'], ['IBKA', 'publish', 'a', 'journal'], ['MIZ', 'Materialien', 'und', 'Informationen', 'zur', 'Zeit', 'Politisches'], ['Journal', 'der', 'Konfessionslosesn', 'und', 'Atheisten', 'Hrsg', 'IBKA', 'eV'], ['MIZVertrieb', 'Postfach', '880', 'D1000', 'Berlin', '41', 'Germany'], ['For', 'atheist', 'books', 'write', 'to'], ['IBDK', 'Internationaler', 'Bucherdienst', 'der', 'Konfessionslosen'], ['Postfach', '3005', 'D3000', 'Hannover', '1', 'Germany'], ['Telephone', '0511211216'], ['Books', '', 'Fiction'], ['THOMAS', 'M', 'DISCH'], ['The', 'Santa', 'Claus', 'Compromise'], ['Short', 'story', '', 'The', 'ultimate', 'proof', 'that', 'Santa', 'exists', '', 'All', 'characters', 'and'], ['events', 'are', 'fictitious', '', 'Any', 'similarity', 'to', 'living', 'or', 'dead', 'gods', '', 'uh', 'well'], ['WALTER', 'M', 'MILLER', 'JR'], ['A', 'Canticle', 'for', 'Leibowitz'], ['One', 'gem', 'in', 'this', 'post', 'atomic', 'doomsday', 'novel', 'is', 'the', 'monks', 'who', 'spent', 'their', 'lives'], ['copying', 'blueprints', 'from', 'Saint', 'Leibowitz', 'filling', 'the', 'sheets', 'of', 'paper', 'with'], ['ink', 'and', 'leaving', 'white', 'lines', 'and', 'letters'], ['EDGAR', 'PANGBORN'], ['Davy'], ['Post', 'atomic', 'doomsday', 'novel', 'set', 'in', 'clerical', 'states', '', 'The', 'church', 'for', 'example'], ['forbids', 'that', 'anyone', 'produce', 'describe', 'or', 'use', 'any', 'substance', 'containing'], ['atoms'], ['PHILIP', 'K', 'DICK'], ['Philip', 'K', 'Dick', 'Dick', 'wrote', 'many', 'philosophical', 'and', 'thoughtprovoking', 'short'], ['stories', 'and', 'novels', '', 'His', 'stories', 'are', 'bizarre', 'at', 'times', 'but', 'very', 'approachable'], ['He', 'wrote', 'mainly', 'SF', 'but', 'he', 'wrote', 'about', 'people', 'truth', 'and', 'religion', 'rather', 'than'], ['technology', '', 'Although', 'he', 'often', 'believed', 'that', 'he', 'had', 'met', 'some', 'sort', 'of', 'God', 'he'], ['remained', 'sceptical', '', 'Amongst', 'his', 'novels', 'the', 'following', 'are', 'of', 'some', 'relevance'], ['Galactic', 'PotHealer'], ['A', 'fallible', 'alien', 'deity', 'summons', 'a', 'group', 'of', 'Earth', 'craftsmen', 'and', 'women', 'to', 'a'], ['remote', 'planet', 'to', 'raise', 'a', 'giant', 'cathedral', 'from', 'beneath', 'the', 'oceans', '', 'When', 'the'], ['deity', 'begins', 'to', 'demand', 'faith', 'from', 'the', 'earthers', 'pothealer', 'Joe', 'Fernwright', 'is'], ['unable', 'to', 'comply', '', 'A', 'polished', 'ironic', 'and', 'amusing', 'novel'], ['A', 'Maze', 'of', 'Death'], ['Noteworthy', 'for', 'its', 'description', 'of', 'a', 'technologybased', 'religion'], ['VALIS'], ['The', 'schizophrenic', 'hero', 'searches', 'for', 'the', 'hidden', 'mysteries', 'of', 'Gnostic'], ['Christianity', 'after', 'reality', 'is', 'fired', 'into', 'his', 'brain', 'by', 'a', 'pink', 'laser', 'beam', 'of'], ['unknown', 'but', 'possibly', 'divine', 'origin', '', 'He', 'is', 'accompanied', 'by', 'his', 'dogmatic', 'and'], ['dismissively', 'atheist', 'friend', 'and', 'assorted', 'other', 'odd', 'characters'], ['The', 'Divine', 'Invasion'], ['God', 'invades', 'Earth', 'by', 'making', 'a', 'young', 'woman', 'pregnant', 'as', 'she', 'returns', 'from'], ['another', 'star', 'system', '', 'Unfortunately', 'she', 'is', 'terminally', 'ill', 'and', 'must', 'be'], ['assisted', 'by', 'a', 'dead', 'man', 'whose', 'brain', 'is', 'wired', 'to', '24hour', 'easy', 'listening', 'music'], ['MARGARET', 'ATWOOD'], ['The', \"Handmaid's\", 'Tale'], ['A', 'story', 'based', 'on', 'the', 'premise', 'that', 'the', 'US', 'Congress', 'is', 'mysteriously'], ['assassinated', 'and', 'fundamentalists', 'quickly', 'take', 'charge', 'of', 'the', 'nation', 'to', 'set', 'it'], ['right', 'again', '', 'The', 'book', 'is', 'the', 'diary', 'of', 'a', \"woman's\", 'life', 'as', 'she', 'tries', 'to', 'live'], ['under', 'the', 'new', 'Christian', 'theocracy', '', \"Women's\", 'right', 'to', 'own', 'property', 'is', 'revoked'], ['and', 'their', 'bank', 'accounts', 'are', 'closed', 'sinful', 'luxuries', 'are', 'outlawed', 'and', 'the'], ['radio', 'is', 'only', 'used', 'for', 'readings', 'from', 'the', 'Bible', '', 'Crimes', 'are', 'punished'], ['retroactively', 'doctors', 'who', 'performed', 'legal', 'abortions', 'in', 'the', 'old', 'world', 'are'], ['hunted', 'down', 'and', 'hanged', '', \"Atwood's\", 'writing', 'style', 'is', 'difficult', 'to', 'get', 'used', 'to'], ['at', 'first', 'but', 'the', 'tale', 'grows', 'more', 'and', 'more', 'chilling', 'as', 'it', 'goes', 'on'], ['VARIOUS', 'AUTHORS'], ['The', 'Bible'], ['This', 'somewhat', 'dull', 'and', 'rambling', 'work', 'has', 'often', 'been', 'criticized', '', 'However', 'it'], ['is', 'probably', 'worth', 'reading', 'if', 'only', 'so', 'that', \"you'll\", 'know', 'what', 'all', 'the', 'fuss', 'is'], ['about', '', 'It', 'exists', 'in', 'many', 'different', 'versions', 'so', 'make', 'sure', 'you', 'get', 'the', 'one'], ['true', 'version'], ['Books', '', 'Nonfiction'], ['PETER', 'DE', 'ROSA'], ['Vicars', 'of', 'Christ', 'Bantam', 'Press', '1988'], ['Although', 'de', 'Rosa', 'seems', 'to', 'be', 'Christian', 'or', 'even', 'Catholic', 'this', 'is', 'a', 'very'], ['enlighting', 'history', 'of', 'papal', 'immoralities', 'adulteries', 'fallacies', 'etc'], ['German', 'translation', 'Gottes', 'erste', 'Diener', 'Die', 'dunkle', 'Seite', 'des', 'Papsttums'], ['DroemerKnaur', '1989'], ['MICHAEL', 'MARTIN'], ['Atheism', 'A', 'Philosophical', 'Justification', 'Temple', 'University', 'Press'], ['Philadelphia', 'USA'], ['A', 'detailed', 'and', 'scholarly', 'justification', 'of', 'atheism', '', 'Contains', 'an', 'outstanding'], ['appendix', 'defining', 'terminology', 'and', 'usage', 'in', 'this', 'necessarily', 'tendentious'], ['area', '', 'Argues', 'both', 'for', 'negative', 'atheism', 'ie', 'the', 'nonbelief', 'in', 'the'], ['existence', 'of', 'gods', 'and', 'also', 'for', 'positive', 'atheism', 'the', 'belief', 'in', 'the'], ['nonexistence', 'of', 'gods', '', 'Includes', 'great', 'refutations', 'of', 'the', 'most'], ['challenging', 'arguments', 'for', 'god', 'particular', 'attention', 'is', 'paid', 'to', 'refuting'], ['contempory', 'theists', 'such', 'as', 'Platinga', 'and', 'Swinburne'], ['541', 'pages', 'ISBN', '0877226423', 'hardcover', 'paperback', 'also', 'available'], ['The', 'Case', 'Against', 'Christianity', 'Temple', 'University', 'Press'], ['A', 'comprehensive', 'critique', 'of', 'Christianity', 'in', 'which', 'he', 'considers'], ['the', 'best', 'contemporary', 'defences', 'of', 'Christianity', 'and', 'ultimately'], ['demonstrates', 'that', 'they', 'are', 'unsupportable', 'andor', 'incoherent'], ['273', 'pages', 'ISBN', '0877227675'], ['JAMES', 'TURNER'], ['Without', 'God', 'Without', 'Creed', 'The', 'Johns', 'Hopkins', 'University', 'Press', 'Baltimore'], ['MD', 'USA'], ['Subtitled', 'The', 'Origins', 'of', 'Unbelief', 'in', 'America', '', 'Examines', 'the', 'way', 'in', 'which'], ['unbelief', 'whether', 'agnostic', 'or', 'atheistic', '', 'became', 'a', 'mainstream', 'alternative'], ['worldview', '', 'Focusses', 'on', 'the', 'period', '17701900', 'and', 'while', 'considering', 'France'], ['and', 'Britain', 'the', 'emphasis', 'is', 'on', 'American', 'and', 'particularly', 'New', 'England'], ['developments', '', 'Neither', 'a', 'religious', 'history', 'of', 'secularization', 'or', 'atheism'], ['Without', 'God', 'Without', 'Creed', 'is', 'rather', 'the', 'intellectual', 'history', 'of', 'the', 'fate'], ['of', 'a', 'single', 'idea', 'the', 'belief', 'that', 'God', 'exists'], ['316', 'pages', 'ISBN', 'hardcover', '080182494X', 'paper', '0801834074'], ['GEORGE', 'SELDES', 'Editor'], ['The', 'great', 'thoughts', 'Ballantine', 'Books', 'New', 'York', 'USA'], ['A', 'dictionary', 'of', 'quotations', 'of', 'a', 'different', 'kind', 'concentrating', 'on', 'statements'], ['and', 'writings', 'which', 'explicitly', 'or', 'implicitly', 'present', 'the', \"person's\", 'philosophy'], ['and', 'worldview', '', 'Includes', 'obscure', 'and', 'often', 'suppressed', 'opinions', 'from', 'many'], ['people', '', 'For', 'some', 'popular', 'observations', 'traces', 'the', 'way', 'in', 'which', 'various'], ['people', 'expressed', 'and', 'twisted', 'the', 'idea', 'over', 'the', 'centuries', '', 'Quite', 'a', 'number', 'of'], ['the', 'quotations', 'are', 'derived', 'from', \"Cardiff's\", 'What', 'Great', 'Men', 'Think', 'of', 'Religion'], ['and', \"Noyes'\", 'Views', 'of', 'Religion'], ['490', 'pages', 'ISBN', 'paper', '034529887X'], ['RICHARD', 'SWINBURNE'], ['The', 'Existence', 'of', 'God', 'Revised', 'Edition', 'Clarendon', 'Paperbacks', 'Oxford'], ['This', 'book', 'is', 'the', 'second', 'volume', 'in', 'a', 'trilogy', 'that', 'began', 'with', 'The', 'Coherence', 'of'], ['Theism', '1977', 'and', 'was', 'concluded', 'with', 'Faith', 'and', 'Reason', '1981', '', 'In', 'this'], ['work', 'Swinburne', 'attempts', 'to', 'construct', 'a', 'series', 'of', 'inductive', 'arguments', 'for', 'the'], ['existence', 'of', 'God', '', 'His', 'arguments', 'which', 'are', 'somewhat', 'tendentious', 'and', 'rely'], ['upon', 'the', 'imputation', 'of', 'late', '20th', 'century', 'western', 'Christian', 'values', 'and'], ['aesthetics', 'to', 'a', 'God', 'which', 'is', 'supposedly', 'as', 'simple', 'as', 'can', 'be', 'conceived', 'were'], ['decisively', 'rejected', 'in', \"Mackie's\", 'The', 'Miracle', 'of', 'Theism', '', 'In', 'the', 'revised'], ['edition', 'of', 'The', 'Existence', 'of', 'God', 'Swinburne', 'includes', 'an', 'Appendix', 'in', 'which', 'he'], ['makes', 'a', 'somewhat', 'incoherent', 'attempt', 'to', 'rebut', 'Mackie'], ['J', 'L', 'MACKIE'], ['The', 'Miracle', 'of', 'Theism', 'Oxford'], ['This', 'posthumous', 'volume', 'contains', 'a', 'comprehensive', 'review', 'of', 'the', 'principal'], ['arguments', 'for', 'and', 'against', 'the', 'existence', 'of', 'God', '', 'It', 'ranges', 'from', 'the', 'classical'], ['philosophical', 'positions', 'of', 'Descartes', 'Anselm', 'Berkeley', 'Hume', 'et', 'al', 'through'], ['the', 'moral', 'arguments', 'of', 'Newman', 'Kant', 'and', 'Sidgwick', 'to', 'the', 'recent', 'restatements'], ['of', 'the', 'classical', 'theses', 'by', 'Plantinga', 'and', 'Swinburne', '', 'It', 'also', 'addresses', 'those'], ['positions', 'which', 'push', 'the', 'concept', 'of', 'God', 'beyond', 'the', 'realm', 'of', 'the', 'rational'], ['such', 'as', 'those', 'of', 'Kierkegaard', 'Kung', 'and', 'Philips', 'as', 'well', 'as', 'replacements', 'for'], ['God', 'such', 'as', \"Lelie's\", 'axiarchism', '', 'The', 'book', 'is', 'a', 'delight', 'to', 'read', '', 'less'], ['formalistic', 'and', 'better', 'written', 'than', \"Martin's\", 'works', 'and', 'refreshingly', 'direct'], ['when', 'compared', 'with', 'the', 'handwaving', 'of', 'Swinburne'], ['JAMES', 'A', 'HAUGHT'], ['Holy', 'Horrors', 'An', 'Illustrated', 'History', 'of', 'Religious', 'Murder', 'and', 'Madness'], ['Prometheus', 'Books'], ['Looks', 'at', 'religious', 'persecution', 'from', 'ancient', 'times', 'to', 'the', 'present', 'day', '', 'and'], ['not', 'only', 'by', 'Christians'], ['Library', 'of', 'Congress', 'Catalog', 'Card', 'Number', '8964079', '1990'], ['NORM', 'R', 'ALLEN', 'JR'], ['African', 'American', 'Humanism', 'an', 'Anthology'], ['See', 'the', 'listing', 'for', 'African', 'Americans', 'for', 'Humanism', 'above'], ['GORDON', 'STEIN'], ['An', 'Anthology', 'of', 'Atheism', 'and', 'Rationalism', 'Prometheus', 'Books'], ['An', 'anthology', 'covering', 'a', 'wide', 'range', 'of', 'subjects', 'including', \"'The\", 'Devil', 'Evil'], ['and', \"Morality'\", 'and', \"'The\", 'History', 'of', \"Freethought'\", '', 'Comprehensive', 'bibliography'], ['EDMUND', 'D', 'COHEN'], ['The', 'Mind', 'of', 'The', 'BibleBeliever', 'Prometheus', 'Books'], ['A', 'study', 'of', 'why', 'people', 'become', 'Christian', 'fundamentalists', 'and', 'what', 'effect', 'it'], ['has', 'on', 'them'], ['Net', 'Resources'], [\"There's\", 'a', 'small', 'mailbased', 'archive', 'server', 'at', 'mantiscouk', 'which', 'carries'], ['archives', 'of', 'old', 'altatheismmoderated', 'articles', 'and', 'assorted', 'other', 'files', '', 'For'], ['more', 'information', 'send', 'mail', 'to', 'archiveservermantiscouk', 'saying'], ['help'], ['send', 'atheismindex'], ['and', 'it', 'will', 'mail', 'back', 'a', 'reply'], ['mathew'], ['ÿ']]\n"
     ]
    }
   ],
   "source": [
    "#Each original document is now represented in the list, ‘texts’, as a list of sentences, and \n",
    "#each sentence is a list of words.\n",
    "\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all sentences from all texts into a single list of sentences\n",
    "all_sentences = []\n",
    "for text in texts:\n",
    "    all_sentences += text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Detection using Gensim Phraser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gensim.models.phrases module provides everything required in a simple form:\n",
    "# Phrase Detection\n",
    "# Give some common terms that can be ignored in phrase detection\n",
    "# For example, 'state_of_affairs' will be detected because 'of' is provided here: \n",
    "# common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
    "# # Create the relevant phrases from the list of sentences:\n",
    "# phrases = Phrases(all_sentences, common_terms=common_terms)\n",
    "# # The Phraser object is used from now on to transform sentences\n",
    "# bigram = Phraser(phrases)\n",
    "\n",
    "# # Applying the Phraser to transform our sentences is simply\n",
    "# all_sentences = list(bigram[all_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'what', 'I', 'am', 'interested', 'in', 'is', 'the', 'original', 'notion', 'you', 'were', 'discussing']\n"
     ]
    }
   ],
   "source": [
    "print(all_sentences[11678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328961"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences[11678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"] # this you do after you get a feel for the kind of paired words in your testtual data\n",
    "phrases = Phrases(all_sentences, common_terms=common_terms)\n",
    "bigram = Phraser(phrases)\n",
    "all_sentences = list(bigram[all_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences[11678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'what', 'I_am', 'interested_in', 'is', 'the', 'original', 'notion', 'you', 'were', 'discussing']\n"
     ]
    }
   ],
   "source": [
    "print(all_sentences[11678])  # after bigramming the texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#‘interested_in’ may indicate an overly greedy application of the phrase detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Word Embeddings using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(all_sentences, \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=200,      # Dimensionality of word embeddings\n",
    "                 workers=2,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=30)       # Number of epochs training over corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1a300f7320>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word embedding size\n",
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53724"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of words in the model\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/miniconda3/envs/py36/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Los_Angeles', 0.4764913320541382),\n",
       " ('California', 0.4720371961593628),\n",
       " ('Florida', 0.45818209648132324),\n",
       " ('AHL', 0.44434309005737305),\n",
       " ('NY', 0.4333398640155792),\n",
       " ('N_Y', 0.4313083291053772),\n",
       " ('1970', 0.425307035446167),\n",
       " ('Wisconsin', 0.424573689699173),\n",
       " ('Albany', 0.42317038774490356),\n",
       " ('City', 0.42270994186401367)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"New_York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/miniconda3/envs/py36/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('car', 0.4875488877296448),\n",
       " ('bike', 0.4857217073440552),\n",
       " ('suspension', 0.46694448590278625),\n",
       " ('speed', 0.45672088861465454),\n",
       " ('motor', 0.45661652088165283),\n",
       " ('accelerator', 0.45547688007354736),\n",
       " ('torque', 0.4486038386821747),\n",
       " ('voltage', 0.44655799865722656),\n",
       " ('clutch', 0.4387759566307068),\n",
       " ('tires', 0.4374878406524658)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
